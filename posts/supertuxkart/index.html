<!doctype html><html class=no-js lang=en-us></html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Learning to play Ice Hockey in SuperTuxKart through Reinforcement Learning</title><meta name=description content><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.96.0"><link href="https://fonts.googleapis.com/css2?family=Jost:wght@300;400;500;600;700&family=Poppins&display=swap" rel=stylesheet><link rel=stylesheet href=https://rolozanod.github.io/css/bootstrap.min.css><link rel=stylesheet href=https://rolozanod.github.io/css/themefisher-fonts.css><link rel=stylesheet href=https://rolozanod.github.io/css/font-awesome.min.css><link rel=stylesheet href=https://rolozanod.github.io/plugins/font-awesome/css/font-awesome.min.css><link rel=stylesheet href=https://rolozanod.github.io/css/owl.carousel.css><link rel=stylesheet href=https://rolozanod.github.io/css/animate.css><link rel=stylesheet href=https://rolozanod.github.io/css/style.css><link rel=stylesheet href=https://rolozanod.github.io/scss/style.min.css><link rel="shortcut icon" href=https://rolozanod.github.io/images/rl.ico type=image/x-icon><link rel=icon href=https://rolozanod.github.io/images/rl.ico type=image/x-icon><link rel=stylesheet href=https://rolozanod.github.io/css/responsive.css><link rel=stylesheet href=https://rolozanod.github.io/css/bootstrap-table.css><script>console.log("Welcome to my site!")</script></head><body id=body><div id=preloader><div class=book><div class=book__page></div><div class=book__page></div><div class=book__page></div></div></div><div class=container><nav class="navbar navbar-fixed-top navigation" id=top-nav><a class="navbar-brand float-none float-lg-left" href=https://rolozanod.github.io><img src=https://rolozanod.github.io/images/rl.ico alt=logo></a>
<button class="navbar-toggler hidden-lg-up float-lg-right" type=button data-toggle=collapse data-target=#navbarResponsive>
<i class=tf-ion-android-menu></i></button><div class="collapse navbar-toggleable-md" id=navbarResponsive><ul class="nav navbar-nav menu float-lg-right" id=top-nav><li class="nav-item active"><a class=nav-link href=https://rolozanod.github.io#home>Home</a></li><li class=nav-item><a class=nav-link href=https://rolozanod.github.io#about>About</a></li><li class=nav-item><a class=nav-link href=https://rolozanod.github.io#service>Skills</a></li><li class=nav-item><a class=nav-link href=https://rolozanod.github.io#posts>Posts</a></li></ul></div></nav></div><div id=content><section class="blog-single section"><div class=container><div class=row><div class="col-lg-2 order-2 order-lg-1"><div class=share-now><a href=# class=scrol>Share</a><div class=sociel-icon><ul><li><a href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2frolozanod.github.io%2fposts%2fsupertuxkart%2f" target=_blank><i class="fa fa-facebook"></i></a></li><li><a href="http://www.twitter.com/intent/tweet?url=https%3a%2f%2frolozanod.github.io%2fposts%2fsupertuxkart%2f" target=_blank><i class="fa fa-twitter"></i></a></li><li><a href="https://www.linkedin.com/cws/share?url=https%3a%2f%2frolozanod.github.io%2fposts%2fsupertuxkart%2f" target=_blank><i class="fa fa-linkedin"></i></a></li></ul></div></div></div><div class="col-lg-10 order-1 order-lg-2"><article class=single-blog><a href=https://rolozanod.github.io/tags/machine-learning class=tag>machine-learning</a><p class=title>Learning to play Ice Hockey in SuperTuxKart through Reinforcement Learning</p><ul class=meta><li>By <a href=https://rolozanod.github.io/about>Rodrigo Lozano</a></li><li><i class="fa fa-clock-o"></i>
August 11, 2023 - 6 min read</li></ul><div class=feature-image><img src=https://rolozanod.github.io/images/blog/pstkrl/rldiag.png alt=banner></div><div class=single-blog-content><h1 id=introduction-to-the-project>Introduction to the project</h1><p>This post is about the final project I did for the Deep Learning subject in the Data Science master at UT Austin.</p><br><p>The aim of the project was to demonstrate Reinforcement Learning (RL) is a viable framework for an agent to attain simple goals in the SuperTuxKart video game.</p><br><h1 id=overview-of-the-project>Overview of the project</h1><br><p>The objective is to train an agent to play Ice Hockey and win by scoring goals. The agent is designed to control two actions: the acceleration and the steering.</p><br><p>The project is implemented in Python using the pystk module, which loads the SuperTuxKart engine. The game is played by two teams of two karts each. PyTorch is used as the machine learning module for the architecture of the artificial neural network (ANN) and the optimization framework.</p><br><p>The training framework is based on Reinforcement Learning using a Policy Gradient, where the agent acts on the environment and records a reward for the decisions made at each step. As the agent plays the game and stores rewards for its actions, the policy gradient algorithm updates a baseline network that estimates the expected reward for each action in a given state. Subsequently, sample gradients are estimated, and the agent&rsquo;s network weights are updated. This iterative process reduces variance during reinforcement learning training.</p><br><p>Through numerous repetitions, the agent learns to play the game by following the puck and hitting it toward the opponentâ€™s goal.</p><br><div class=container><div id=player-wrapper class=RLIceHockey></div></div><script type=text/javascript src=https://cdn.jsdelivr.net/npm/@clappr/player@latest/dist/clappr.min.js></script><script>var playerElement=document.getElementById("player-wrapper"),player=new Clappr.Player({source:"/vid/blog/pstkrl/test_vs_geoffrey.mp4",mute:!0,height:360,width:640});player.attachTo(playerElement)</script><ul><li>The agent trained in this project controls the blue karts in the video.</li></ul><br><h1 id=deep-learning-approach>Deep Learning approach</h1><br><p>The ANN architecture building block is composed of fully connected linear layers and non-linear activations. Two building blocks are employed in the main architecture as depicted in figure bellow. Each neural network focuses on one of the two main actions: acceleration and steering.</p><p><img src=/images/blog/pstkrl/ann.png alt="Agent Deep Learning Artificial Neural Network Architecture"></p><br><p>As mentioned in the overview, a policy gradient was used to train the agent. This means the training objective is to optimize an ANN that determines the best course of action (a policy Ï€) given the current game state.</p><p><img src=/images/blog/pstkrl/rldiag.png alt="Policy gradient algorithm procedure"></p><br><p>The agent must take an action (a) given state (s) using its current policy which is determined by the ANN.</p><blockquote><p>ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘› = ğ´ğ‘ğ‘(ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘’)</p></blockquote><p>With this action, the agent interacts with the environment, which determines the new state and a reward. The cycle repeats, accumulating rewards as the agent continues to interact with the environment.</p><br><p>During this phase, off-policy sampling is introduced. The agent receives the REINFORCE reward and also considers the outcome 60 steps ahead, measuring the reward or penalty based on whether a goal was scored or conceded, and how close the puck came to the goalpost compared to the current step. This adjustment is then modulated using an importance sampling approach to guide the agent toward actions that maximize the match outcome: scoring goals while preventing the opponent from scoring.</p><br><h1 id=results>Results</h1><br><p>The agent was first trained on an RL basis and played against itself or the basic AI.</p><br><table><thead><tr><th style=text-align:center>Pretrained AI Goals</th><th style=text-align:center>ANN Agent Goals</th></tr></thead><tbody><tr><td style=text-align:center>87</td><td style=text-align:center>2</td></tr></tbody></table><br><p>REINFORCE enables the agent to learn how to navigate the field but does not result in as many goals as expected when playing against the AI. After REINFORCE, the policy gradient initiates, and the agent faces the more advanced pretrained AIs.</p><br><table><thead><tr><th style=text-align:center>Other DL AI Goals</th><th style=text-align:center>ANN Agent Goals</th></tr></thead><tbody><tr><td style=text-align:center>61</td><td style=text-align:center>15</td></tr></tbody></table><br><blockquote><p>Policy gradient improved the goal scoring metric with 41 games played and 15 goals (38%) vs 2 goals scored in 75 games (3%).</p></blockquote></div></article><div class=blog-single-presentation><ul><li><a href=/posts/rps_ml/ class=tag>PREVIOUS</a>
<a href=/posts/rps_ml/ class=title>RPS Vision ML</a>
<i class="fa fa-clock-o"></i>
December 19, 2022 - 3 min</li><li><a href=/posts/mexico_poverty/ class=tag>Next</a>
<a href=/posts/mexico_poverty/ class=title>Clustering Mexico's neighborhoods and economic activities</a>
<i class="fa fa-clock-o"></i>
January 7, 2024 - 15 min</li></ul></div></div></div></div></section></div><footer class=footer><div class=container-fluid><div class=row><div class="col-lg-12 mx-auto text-center"><div class=block><p><a href=https://rolozanod.github.io>Rodrigo Lozano</a></p></div></div></div><div class=row><div class="col-lg-12 mx-auto text-center"><div class=sociale-icon><ul class=main-nav-social><li><a href=https://github.com/rolozanod/><i class="fa fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/rolozanod/><i class="fa fa-linkedin"></i></a></li></ul></div></div></div></div></footer><script src=https://rolozanod.github.io/js/vendor/jquery-2.1.1.min.js></script>
<script src=https://rolozanod.github.io/js/bootstrap.min.js></script>
<script src=https://rolozanod.github.io/js/vendor/modernizr-2.6.2.min.js></script>
<script src=https://rolozanod.github.io/js/jquery.lwtCountdown-1.0.js></script>
<script src=https://rolozanod.github.io/js/owl.carousel.min.js></script>
<script src=https://rolozanod.github.io/js/jquery.validate.min.js></script>
<script src=https://rolozanod.github.io/js/jquery.form.js></script>
<script src=https://rolozanod.github.io/js/jquery.nav.js></script>
<script src=https://rolozanod.github.io/js/wow.min.js></script>
<script src=https://rolozanod.github.io/js/main.js></script></body></html></body></html>