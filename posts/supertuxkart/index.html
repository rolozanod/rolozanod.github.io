<!doctype html><html class=no-js lang=en-us></html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Learning to play Ice Hockey in SuperTuxKart through Reinforcement Learning</title><meta name=description content><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.96.0"><link href="https://fonts.googleapis.com/css2?family=Jost:wght@300;400;500;600;700&family=Poppins&display=swap" rel=stylesheet><link rel=stylesheet href=https://rolozanod.github.io/css/bootstrap.min.css><link rel=stylesheet href=https://rolozanod.github.io/css/themefisher-fonts.css><link rel=stylesheet href=https://rolozanod.github.io/css/font-awesome.min.css><link rel=stylesheet href=https://rolozanod.github.io/plugins/font-awesome/css/font-awesome.min.css><link rel=stylesheet href=https://rolozanod.github.io/css/owl.carousel.css><link rel=stylesheet href=https://rolozanod.github.io/css/animate.css><link rel=stylesheet href=https://rolozanod.github.io/css/style.css><link rel=stylesheet href=https://rolozanod.github.io/scss/style.min.css><link rel="shortcut icon" href=https://rolozanod.github.io/images/rl.ico type=image/x-icon><link rel=icon href=https://rolozanod.github.io/images/rl.ico type=image/x-icon><link rel=stylesheet href=https://rolozanod.github.io/css/responsive.css><script>console.log("Welcome to my site!")</script></head><body id=body><div id=preloader><div class=book><div class=book__page></div><div class=book__page></div><div class=book__page></div></div></div><div class=container><nav class="navbar navbar-fixed-top navigation" id=top-nav><a class="navbar-brand float-none float-lg-left" href=https://rolozanod.github.io><img src=https://rolozanod.github.io/images/rl.ico alt=logo></a>
<button class="navbar-toggler hidden-lg-up float-lg-right" type=button data-toggle=collapse data-target=#navbarResponsive>
<i class=tf-ion-android-menu></i></button><div class="collapse navbar-toggleable-md" id=navbarResponsive><ul class="nav navbar-nav menu float-lg-right" id=top-nav><li class="nav-item active"><a class=nav-link href=https://rolozanod.github.io#home>Home</a></li><li class=nav-item><a class=nav-link href=https://rolozanod.github.io#about>About</a></li><li class=nav-item><a class=nav-link href=https://rolozanod.github.io#service>Skills</a></li><li class=nav-item><a class=nav-link href=https://rolozanod.github.io#posts>Posts</a></li></ul></div></nav></div><div id=content><section class="blog-single section"><div class=container><div class=row><div class="col-lg-2 order-2 order-lg-1"><div class=share-now><a href=# class=scrol>Share</a><div class=sociel-icon><ul><li><a href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2frolozanod.github.io%2fposts%2fsupertuxkart%2f" target=_blank><i class="fa fa-facebook"></i></a></li><li><a href="http://www.twitter.com/intent/tweet?url=https%3a%2f%2frolozanod.github.io%2fposts%2fsupertuxkart%2f" target=_blank><i class="fa fa-twitter"></i></a></li><li><a href="https://www.linkedin.com/cws/share?url=https%3a%2f%2frolozanod.github.io%2fposts%2fsupertuxkart%2f" target=_blank><i class="fa fa-linkedin"></i></a></li></ul></div></div></div><div class="col-lg-10 order-1 order-lg-2"><article class=single-blog><a href=https://rolozanod.github.io/tags/machine-learning class=tag>machine-learning</a><p class=title>Learning to play Ice Hockey in SuperTuxKart through Reinforcement Learning</p><ul class=meta><li>By <a href=https://rolozanod.github.io/about>Rodrigo Lozano</a></li><li><i class="fa fa-clock-o"></i>
August 11, 2023 - 6 min read</li></ul><div class=feature-image><img src=https://rolozanod.github.io/images/blog/pstkrl/rldiag.png alt=banner></div><div class=single-blog-content><h1 id=introduction-to-the-project>Introduction to the project</h1><p>This post is about the final project I did for the Deep Learning subject in the Data Science master at UT Austin.</p><br><p>The aim of the project was to demonstrate Reinforcement Learning (RL) is a viable framework for an agent to attain simple goals in the SuperTuxKart video game.</p><br><h1 id=overview-of-the-project>Overview of the project</h1><br><p>The objective is to train an agent to play Ice Hockey and win by scoring goals. The agent is designed to control two actions: the acceleration and the steering.</p><br><p>The project is set up in Python using the pystk module which loads the SuperTuxKart engine. The game is played by 2 teams which are composed of 2 karts each. Pytorch is used as the Machine Learning module for the architecture of the Artificial Neural Network (ANN) and the optimization framework.</p><br><p>The training framework is based on Reinforcement Learning using a Policy Gradient, where the agent acts on the environment and records a reward for the decisions made at each step. As the agent plays the game and stores rewards for actions taken, the Policy Gradient algorithm updates a baseline network that sets the expected reward for each action given to each state. Afterwards, sample gradients are estimated, and the agent network weights are updated. This is done repeatedly to train the agent iteratively and doing it so reduces the variance when training through reinforcement learning.</p><br><p>Over numerous repetitions, the agent will learn to play the game by following the puck and hitting it towards the opponentâ€™s goal.</p><br><div class=container><div id=player-wrapper class=RLIceHockey></div></div><script type=text/javascript src=https://cdn.jsdelivr.net/npm/@clappr/player@latest/dist/clappr.min.js></script><script>var playerElement=document.getElementById("player-wrapper"),player=new Clappr.Player({source:"/vid/blog/pstkrl/test_vs_geoffrey.mp4",mute:!0,height:360,width:640});player.attachTo(playerElement)</script><ul><li>The agent trained in this project controls the blue karts in the video.</li></ul><br><h1 id=deep-learning-approach>Deep Learning approach</h1><br><p>The ANN architecture building block is composed of fully connected linear layers and non-linear activations. Two building blocks are employed in the main architecture as depicted in figure bellow. Each neural network is focused on one of the two main actions: the acceleration and steering of the kart.</p><p><img src=/images/blog/pstkrl/ann.png alt="Agent Deep Learning Artificial Neural Network Architecture"></p><br><p>As mentioned in the overview, a policy gradient was employed to train the agent. This means that the objective of the training is to optimize an ANN that devises the best course of action (a policy Ï€) given the presented state of the game.</p><p><img src=/images/blog/pstkrl/rldiag.png alt="Policy gradient algorithm procedure"></p><br><p>The agent must take an action (a) given state (s) using its current policy which is determined by the ANN.</p><blockquote><p>ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘› = ğ´ğ‘ğ‘(ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘’)</p></blockquote><p>With this action, the agent acts upon the environment which determines the new state and a reward for the action taken. The whole cycle begins again, collecting even more rewards as the agent acts upon the environment.</p><br><p>During this phase, off-policy sampling is introduced. The agent receives the REINFORCE reward and additionally looks 60 steps ahead and measures the reward or penalty if any goal was scored or received; as well as how close the puck got to the goalpost when compared with the current step. This adjustment is then modulated with an importance sampling approach to steer the agent towards the actions that yield the best match outcome which is scoring goals while avoiding opponents score goals.</p><br><h1 id=results>Results</h1><br><p>The agent was first trained on an RL basis and played against itself or the basic AI.</p><br><table><thead><tr><th style=text-align:center>Pretrained AI Goals</th><th style=text-align:center>ANN Agent Goals</th></tr></thead><tbody><tr><td style=text-align:center>87</td><td style=text-align:center>2</td></tr></tbody></table><br><p>REINFORCE takes the agent as far as learning how to navigate the field but does not score as many goals as one would expect when playing against the AI. After REINFORCE, the policy gradient initiates, and the agent faces the more advanced pretrained AIs.</p><br><table><thead><tr><th style=text-align:center>Other DL AI Goals</th><th style=text-align:center>ANN Agent Goals</th></tr></thead><tbody><tr><td style=text-align:center>61</td><td style=text-align:center>15</td></tr></tbody></table><br><blockquote><p>Policy gradient improved the goal scoring metric with 41 games played and 15 goals (38%) vs 2 goals scored in 75 games (3%).</p></blockquote></div></article><div class=blog-single-presentation><ul><li><a href=/posts/rps_ml/ class=tag>PREVIOUS</a>
<a href=/posts/rps_ml/ class=title>RPS Vision ML</a>
<i class="fa fa-clock-o"></i>
December 19, 2022 - 3 min</li><li><a href=/posts/mexico_poverty/ class=tag>Next</a>
<a href=/posts/mexico_poverty/ class=title>Clustering Mexico's neighborhoods and economic activities</a>
<i class="fa fa-clock-o"></i>
January 7, 2024 - 15 min</li></ul></div></div></div></div></section></div><footer class=footer><div class=container-fluid><div class=row><div class="col-lg-12 mx-auto text-center"><div class=block><p><a href=https://rolozanod.github.io>Rodrigo Lozano</a></p></div></div></div><div class=row><div class="col-lg-12 mx-auto text-center"><div class=sociale-icon><ul class=main-nav-social><li><a href=https://github.com/rolozanod/><i class="fa fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/rolozanod/><i class="fa fa-linkedin"></i></a></li></ul></div></div></div></div></footer><script src=https://rolozanod.github.io/js/vendor/jquery-2.1.1.min.js></script>
<script src=https://rolozanod.github.io/js/bootstrap.min.js></script>
<script src=https://rolozanod.github.io/js/vendor/modernizr-2.6.2.min.js></script>
<script src=https://rolozanod.github.io/js/jquery.lwtCountdown-1.0.js></script>
<script src=https://rolozanod.github.io/js/owl.carousel.min.js></script>
<script src=https://rolozanod.github.io/js/jquery.validate.min.js></script>
<script src=https://rolozanod.github.io/js/jquery.form.js></script>
<script src=https://rolozanod.github.io/js/jquery.nav.js></script>
<script src=https://rolozanod.github.io/js/wow.min.js></script>
<script src=https://rolozanod.github.io/js/main.js></script></body></html></body></html>